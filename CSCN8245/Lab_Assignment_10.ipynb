{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 10: <br>\n",
    "### Student Name:Amit Ghogre\n",
    "### Student ID:8833038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment targets to assure that the students understood basic IR concepts.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Implementing an IR System (10/16)**<br>\n",
    "\n",
    "Consider a collection of 1000 documents and a set of 10 queries. Implement an IR system based on the Vector Space Model (VSM) using TF-IDF weighting.<br>\n",
    "\n",
    "Dataset:<br>\n",
    "\n",
    "- 1000 documents (text content for each document)\n",
    "- 10 sample queries <br>\n",
    "IR System:<br>\n",
    "\n",
    "Implement TF-IDF calculation for document-term matrix construction. <br>\n",
    "Develop a cosine similarity-based retrieval system to rank documents for each query. <br>\n",
    "Rank the top 10 documents for each query using the IR system. <br>\n",
    "Evaluation: <br>\n",
    "\n",
    "Compute Precision at k (P@k) for k=5, k=6, and k=10 for each query.<br>\n",
    "Calculate Mean Average Precision (MAP) across all queries. <br>\n",
    "Calculate the Mean Reciprocal Rank (MRR) across all queries.(3) <br><br>\n",
    "**Part 2: Assessing Inter-Annotator Agreement (6/16)**<br>\n",
    "\n",
    "Given the relevance assessments by three different annotators for a set of documents:<br>\n",
    "\n",
    "Annotator 1,2 and 3 relevance assessments<br>\n",
    "\n",
    "You are expected to: <br>\n",
    "\n",
    "Compute pairwise Cohen's Kappa values for the annotators' relevance assessments.<br>\n",
    "Discuss the observed agreement levels among annotators.<br>\n",
    "Explain how to improve the kappa value if we are not satisfied with the kappa.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------\n",
    "- Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is transforming various industries.\",\n",
    "    \"Natural language processing helps in text analysis.\",\n",
    "    \"AI algorithms can improve decision-making processes.\",\n",
    "    \"Data science involves extracting insights from data.\",\n",
    "    \"Robotics is a field combining hardware and software.\",\n",
    "    \"Deep learning models require large amounts of data.\",\n",
    "    \"Blockchain technology secures digital transactions.\",\n",
    "    \"Cloud computing offers scalable computing power.\",\n",
    "    \"Virtual reality provides immersive experiences.\",\n",
    "    \"Augmented reality enhances real-world environments.\",\n",
    "    \"Internet of Things connects devices for data exchange.\",\n",
    "    \"Biometric authentication ensures secure access.\",\n",
    "    \"Quantum computing promises faster computations.\",\n",
    "    \"Cybersecurity protects against digital threats.\",\n",
    "    \"Ethical considerations in AI development are crucial.\",\n",
    "    \"Healthcare benefits from AI-driven diagnostics.\",\n",
    "    \"E-commerce relies on personalized recommendation systems.\",\n",
    "    \"Autonomous vehicles revolutionize transportation.\",\n",
    "    \"Smart cities utilize IoT for efficient operations.\",\n",
    "    \"Social media analysis aids in understanding trends.\",\n",
    "    \"Predictive analytics anticipates future outcomes.\",\n",
    "    \"Remote work trends increase reliance on digital tools.\",\n",
    "    \"Energy efficiency through smart grids is vital.\",\n",
    "    \"Fintech innovations reshape financial services.\",\n",
    "    \"Data privacy concerns arise in the era of big data.\",\n",
    "    \"Artificial general intelligence remains a challenge.\",\n",
    "    \"Human-computer interaction shapes user experiences.\",\n",
    "    \"Big data analytics drives informed decision-making.\",\n",
    "    \"Climate change predictions benefit from AI models.\",\n",
    "    \"Bioinformatics applies computational techniques to biology.\",\n",
    "    \"Robotic process automation streamlines workflows.\",\n",
    "    \"Industry 4.0 integrates AI with manufacturing.\",\n",
    "    \"Sentiment analysis detects emotions in text data.\",\n",
    "    \"Reinforcement learning powers autonomous agents.\",\n",
    "    \"Data visualization simplifies complex information.\",\n",
    "    \"Edge computing reduces latency in data processing.\",\n",
    "    \"Smart farming optimizes agricultural practices.\",\n",
    "    \"AI in education enhances personalized learning.\",\n",
    "    \"Natural disaster predictions leverage machine learning.\",\n",
    "    \"Media recommendation systems personalize content.\",\n",
    "    \"Speech recognition enables hands-free interactions.\",\n",
    "    \"Genetic algorithms mimic natural selection.\",\n",
    "    \"Neural networks simulate the human brain.\",\n",
    "    \"Behavioral analytics uncovers patterns in behavior.\",\n",
    "    \"Spatial analysis benefits from geospatial data.\",\n",
    "    \"Explainable AI improves transparency in models.\",\n",
    "    \"AI ethics guide responsible technology development.\",\n",
    "    \"Prescriptive analytics offers actionable insights.\",\n",
    "    \"Supply chain optimization employs predictive models.\",\n",
    "    \"Emotion AI detects emotions in facial expressions.\",\n",
    "    \"Distributed ledger technology ensures secure transactions.\",\n",
    "    \"Biological data analysis aids in medical research.\",\n",
    "    \"Smart grid technology enhances energy distribution.\",\n",
    "    \"AI-powered chatbots automate customer support.\",\n",
    "    \"Machine translation breaks language barriers.\",\n",
    "    \"Personalized medicine tailors treatments to individuals.\",\n",
    "    \"Data-driven marketing optimizes customer engagement.\",\n",
    "    \"Smart home devices enhance living experiences.\",\n",
    "    \"Time series forecasting predicts future trends.\",\n",
    "    \"AI-driven creativity challenges human capabilities.\",\n",
    "    \"Intelligent document processing automates data extraction.\",\n",
    "    \"Graph analytics explores relationships in networks.\",\n",
    "    \"Adversarial attacks pose challenges to AI security.\",\n",
    "    \"Predictive maintenance minimizes equipment downtime.\",\n",
    "    \"Spatial reasoning enhances AI navigation systems.\",\n",
    "    \"Privacy-preserving techniques protect sensitive data.\",\n",
    "    \"Automated decision-making raises ethical concerns.\",\n",
    "    \"Behavioral biometrics verifies user identities.\",\n",
    "    \"Explainable recommendations increase user trust.\",\n",
    "    \"Quantum machine learning explores quantum states.\",\n",
    "    \"Internet censorship detection uses AI techniques.\",\n",
    "    \"Smart wearables monitor health and fitness.\",\n",
    "    \"Intelligent tutoring systems adapt to student needs.\",\n",
    "    \"Graph neural networks model complex relationships.\",\n",
    "    \"AI in sports analytics improves performance analysis.\",\n",
    "    \"Facial recognition technology raises privacy debates.\",\n",
    "    \"Digital twin technology replicates physical systems.\",\n",
    "    \"Emotion detection in video content aids analysis.\",\n",
    "    \"Neuromorphic computing mimics brain structure.\",\n",
    "    \"Robotic surgery enhances precision in operations.\",\n",
    "    \"AI-powered language translation assists global communication.\",\n",
    "    \"Automated content moderation filters online content.\",\n",
    "    \"Network anomaly detection identifies security threats.\",\n",
    "    \"Predictive policing uses data to prevent crime.\",\n",
    "    \"Quantum cryptography ensures secure communications.\",\n",
    "    \"AI-generated art challenges traditional creativity.\",\n",
    "    \"Ethical considerations in autonomous vehicles are debated.\",\n",
    "    \"Adaptive learning systems personalize educational content.\",\n",
    "    \"Biomedical image analysis aids in disease diagnosis.\",\n",
    "    \"Explainable computer vision interprets image features.\",\n",
    "    \"AI-driven personalization enhances user experiences.\",\n",
    "    \"Conversational AI improves human-like interactions.\",\n",
    "    \"Federated learning protects individual data privacy.\",\n",
    "    \"Human-centered AI design prioritizes user needs.\",\n",
    "    \"Quantum annealing solves optimization problems.\",\n",
    "    \"Behavior-based authentication enhances security.\",\n",
    "    \"AI in music composition transforms creative processes.\",\n",
    "    \"Semantic search improves information retrieval.\",\n",
    "    \"Recommender systems optimize user preferences.\",\n",
    "    \"Information Retrieval systems are outdated without neural networks\"\n",
    "]\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are the impacts of AI on healthcare?\",\n",
    "    \"How does machine learning improve financial services?\",\n",
    "    \"What is the role of AI in autonomous vehicles?\",\n",
    "    \"Explain the applications of natural language processing.\",\n",
    "    \"How does robotics benefit from AI integration?\",\n",
    "    \"What are the challenges in implementing AI in education?\",\n",
    "    \"How does data science contribute to climate change predictions?\",\n",
    "    \"What are the ethical considerations in AI development?\",\n",
    "    \"Explain the significance of AI in smart cities.\",\n",
    "    \"How does AI enhance cybersecurity measures?\"\n",
    "]\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "ground_truth =[[3, 74, 38, 92, 71, 72, 98, 48, 18, 100], \n",
    "                [12, 26, 52, 54, 21, 63, 64, 45, 14, 83],\n",
    "                [58, 77, 62, 31, 6, 61, 36, 96, 85, 18], \n",
    "                [99, 62, 98, 34, 63, 79, 43, 31, 3, 16],\n",
    "                [8, 88, 73, 82, 37, 25, 34, 87, 66, 58], \n",
    "                [90, 40, 84, 64, 34, 2, 73, 23, 59, 89],\n",
    "                [80, 10, 86, 21, 68, 37, 83, 57, 6, 98],\n",
    "                [22, 3, 2, 44, 56, 80, 50, 63, 87, 13],\n",
    "                [1, 18, 22, 44, 99, 72, 24, 95, 10, 87],\n",
    "                [31, 10, 56, 50, 75, 4, 18, 85, 84, 74]\n",
    "                           ]\n",
    "print(len(ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top documents for query: What are the impacts of AI on healthcare?\n",
      "Healthcare benefits from AI-driven diagnostics.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "Ethical considerations in AI development are crucial.\n",
      "Neural networks simulate the human brain.\n",
      "E-commerce relies on personalized recommendation systems.\n",
      "Ethical considerations in autonomous vehicles are debated.\n",
      "Remote work trends increase reliance on digital tools.\n",
      "Information Retrieval systems are outdated without neural networks\n",
      "Deep learning models require large amounts of data.\n",
      "Internet of Things connects devices for data exchange.\n",
      "\n",
      "Top documents for query: How does machine learning improve financial services?\n",
      "Fintech innovations reshape financial services.\n",
      "Natural disaster predictions leverage machine learning.\n",
      "Machine learning is transforming various industries.\n",
      "Quantum machine learning explores quantum states.\n",
      "AI algorithms can improve decision-making processes.\n",
      "Machine translation breaks language barriers.\n",
      "AI in education enhances personalized learning.\n",
      "Reinforcement learning powers autonomous agents.\n",
      "Federated learning protects individual data privacy.\n",
      "Adaptive learning systems personalize educational content.\n",
      "\n",
      "Top documents for query: What is the role of AI in autonomous vehicles?\n",
      "Autonomous vehicles revolutionize transportation.\n",
      "Ethical considerations in autonomous vehicles are debated.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "Neural networks simulate the human brain.\n",
      "Reinforcement learning powers autonomous agents.\n",
      "Machine learning is transforming various industries.\n",
      "AI in education enhances personalized learning.\n",
      "Energy efficiency through smart grids is vital.\n",
      "Deep learning models require large amounts of data.\n",
      "Explainable AI improves transparency in models.\n",
      "\n",
      "Top documents for query: Explain the applications of natural language processing.\n",
      "Natural language processing helps in text analysis.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "Neural networks simulate the human brain.\n",
      "Machine translation breaks language barriers.\n",
      "Genetic algorithms mimic natural selection.\n",
      "Natural disaster predictions leverage machine learning.\n",
      "Intelligent document processing automates data extraction.\n",
      "Edge computing reduces latency in data processing.\n",
      "AI-powered language translation assists global communication.\n",
      "Deep learning models require large amounts of data.\n",
      "\n",
      "Top documents for query: How does robotics benefit from AI integration?\n",
      "Climate change predictions benefit from AI models.\n",
      "Healthcare benefits from AI-driven diagnostics.\n",
      "Robotics is a field combining hardware and software.\n",
      "Spatial analysis benefits from geospatial data.\n",
      "Data science involves extracting insights from data.\n",
      "AI in education enhances personalized learning.\n",
      "Explainable AI improves transparency in models.\n",
      "AI-driven personalization enhances user experiences.\n",
      "Spatial reasoning enhances AI navigation systems.\n",
      "AI-driven creativity challenges human capabilities.\n",
      "\n",
      "Top documents for query: What are the challenges in implementing AI in education?\n",
      "AI in education enhances personalized learning.\n",
      "Ethical considerations in AI development are crucial.\n",
      "Ethical considerations in autonomous vehicles are debated.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "AI-driven creativity challenges human capabilities.\n",
      "AI-generated art challenges traditional creativity.\n",
      "Explainable AI improves transparency in models.\n",
      "Adversarial attacks pose challenges to AI security.\n",
      "AI in sports analytics improves performance analysis.\n",
      "Neural networks simulate the human brain.\n",
      "\n",
      "Top documents for query: How does data science contribute to climate change predictions?\n",
      "Climate change predictions benefit from AI models.\n",
      "Data science involves extracting insights from data.\n",
      "Predictive policing uses data to prevent crime.\n",
      "Natural disaster predictions leverage machine learning.\n",
      "Bioinformatics applies computational techniques to biology.\n",
      "Personalized medicine tailors treatments to individuals.\n",
      "Adversarial attacks pose challenges to AI security.\n",
      "Intelligent tutoring systems adapt to student needs.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "Data visualization simplifies complex information.\n",
      "\n",
      "Top documents for query: What are the ethical considerations in AI development?\n",
      "Ethical considerations in AI development are crucial.\n",
      "Ethical considerations in autonomous vehicles are debated.\n",
      "AI ethics guide responsible technology development.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "Neural networks simulate the human brain.\n",
      "Automated decision-making raises ethical concerns.\n",
      "AI in education enhances personalized learning.\n",
      "Information Retrieval systems are outdated without neural networks\n",
      "Explainable AI improves transparency in models.\n",
      "AI in sports analytics improves performance analysis.\n",
      "\n",
      "Top documents for query: Explain the significance of AI in smart cities.\n",
      "Data privacy concerns arise in the era of big data.\n",
      "Smart cities utilize IoT for efficient operations.\n",
      "Neural networks simulate the human brain.\n",
      "AI in education enhances personalized learning.\n",
      "Deep learning models require large amounts of data.\n",
      "Explainable AI improves transparency in models.\n",
      "Internet of Things connects devices for data exchange.\n",
      "AI in sports analytics improves performance analysis.\n",
      "Smart farming optimizes agricultural practices.\n",
      "Smart grid technology enhances energy distribution.\n",
      "\n",
      "Top documents for query: How does AI enhance cybersecurity measures?\n",
      "Cybersecurity protects against digital threats.\n",
      "Smart home devices enhance living experiences.\n",
      "AI in education enhances personalized learning.\n",
      "Explainable AI improves transparency in models.\n",
      "AI-driven personalization enhances user experiences.\n",
      "Spatial reasoning enhances AI navigation systems.\n",
      "AI-driven creativity challenges human capabilities.\n",
      "AI in sports analytics improves performance analysis.\n",
      "Industry 4.0 integrates AI with manufacturing.\n",
      "Conversational AI improves human-like interactions.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample documents and queries\n",
    "#documents = [\"Document 1 text\", \"Document 2 text\", \"Document 3 text\", ...]\n",
    "#queries = [\"Query 1 text\", \"Query 2 text\", \"Query 3 text\", ...]\n",
    "\n",
    "# Get TF-IDF matrix and vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Loop through queries\n",
    "for query in queries:\n",
    "    # Vectorize the query\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarity between query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    \n",
    "    # Get indices of top 10 relevant documents\n",
    "    top_results = cosine_similarities[0].argsort()[-10:][::-1]\n",
    "\n",
    "    # Output top documents\n",
    "    print(f\"\\nTop documents for query: {query}\")\n",
    "    for idx in top_results:\n",
    "        print(documents[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## TODO: Implement your solution for part 1\\n\\n\\ndef get_tfidf_matrix(documents):\\n    vectorizer = TfidfVectorizer()\\n    tfidf_matrix = vectorizer.fit_transform(documents)\\n    return vectorizer, tfidf_matrix\\n\\ndef get_top_documents(query, vectorizer, tfidf_matrix, documents, top_n=10):\\n    query_vector = vectorizer.transform([query])\\n    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\\n    top_results = cosine_similarities[0].argsort()[-top_n:][::-1]\\n    top_documents = [documents[idx] for idx in top_results]\\n    return top_documents\\n\\ndef main():\\n    \\n    # Get TF-IDF matrix and vectorizer\\n    vectorizer, tfidf_matrix = get_tfidf_matrix(documents)\\n\\n    # Loop through queries\\n    for query in queries:\\n        # Get top documents for the query\\n        top_documents = get_top_documents(query, vectorizer, tfidf_matrix, documents)\\n\\n        # Output top documents\\n        print(f\"\\nTop documents for query: {query}\")\\n        for doc in top_documents:\\n            print(doc)\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''## TODO: Implement your solution for part 1\n",
    "\n",
    "\n",
    "def get_tfidf_matrix(documents):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def get_top_documents(query, vectorizer, tfidf_matrix, documents, top_n=10):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    top_results = cosine_similarities[0].argsort()[-top_n:][::-1]\n",
    "    top_documents = [documents[idx] for idx in top_results]\n",
    "    return top_documents\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Get TF-IDF matrix and vectorizer\n",
    "    vectorizer, tfidf_matrix = get_tfidf_matrix(documents)\n",
    "\n",
    "    # Loop through queries\n",
    "    for query in queries:\n",
    "        # Get top documents for the query\n",
    "        top_documents = get_top_documents(query, vectorizer, tfidf_matrix, documents)\n",
    "\n",
    "        # Output top documents\n",
    "        print(f\"\\nTop documents for query: {query}\")\n",
    "        for doc in top_documents:\n",
    "            print(doc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(retrieved_docs, relevant_docs, k):\n",
    "    intersection = set(retrieved_docs[:k]) & relevant_docs\n",
    "    return len(intersection) / k\n",
    "\n",
    "def calculate_average_precision(retrieved_docs, relevant_docs):\n",
    "    ap_sum = 0\n",
    "    matching_docs = 0\n",
    "    for rank, doc_id in enumerate(retrieved_docs):\n",
    "        if doc_id in relevant_docs:\n",
    "            matching_docs += 1\n",
    "            ap_sum += matching_docs / (rank + 1)\n",
    "    return ap_sum / len(relevant_docs)\n",
    "\n",
    "def calculate_reciprocal_rank(retrieved_docs, relevant_docs):\n",
    "    for rank, doc_id in enumerate(retrieved_docs):\n",
    "        if doc_id in relevant_docs:\n",
    "            return 1 / (rank + 1)\n",
    "    return 0\n",
    "\n",
    "p_5 = []\n",
    "p_6 = []\n",
    "p_10 = []\n",
    "avg_pres = []\n",
    "r_ranks = []\n",
    "\n",
    "for query_index, ground_truth_docs in enumerate(ground_truth):\n",
    "    relevant_docs = set(ground_truth_docs)\n",
    "    retrieved_docs = top_results\n",
    "\n",
    "    p_5.append(calculate_precision(retrieved_docs, relevant_docs, 5))\n",
    "    p_6.append(calculate_precision(retrieved_docs, relevant_docs, 6))\n",
    "    p_10.append(calculate_precision(retrieved_docs, relevant_docs, 10))\n",
    "\n",
    "    avg_pres.append(calculate_average_precision(retrieved_docs, relevant_docs))\n",
    "\n",
    "    r_ranks.append(calculate_reciprocal_rank(retrieved_docs, relevant_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 5=  0.12\n",
      "Precision at 6=  0.13333333333333333\n",
      "Precision at 10=  0.13999999999999999\n",
      "Mean Average Precision (MAP)= 0.047396825396825396\n",
      "Mean Reciprocal Rank (MRR)= 0.27555555555555555\n"
     ]
    }
   ],
   "source": [
    "map_score = sum(avg_pres) / len(avg_pres)\n",
    "mrr_score = sum(r_ranks) / len(r_ranks)\n",
    "\n",
    "print(f\"Precision at 5=  {sum(p_5) / len(p_5)}\")\n",
    "print(f\"Precision at 6=  {sum(p_6) / len(p_6)}\")\n",
    "print(f\"Precision at 10=  {sum(p_10) / len(p_10)}\")\n",
    "print(f\"Mean Average Precision (MAP)= {map_score}\")\n",
    "print(f\"Mean Reciprocal Rank (MRR)= {mrr_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "- Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is not relevant, 1 is relevant\n",
    "annotator1_relevance = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]  \n",
    "annotator2_relevance = [1, 1, 1, 0, 1, 0, 0, 1, 1, 1]  \n",
    "annotator3_relevance = [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa Annotator 1 & Annotator 2: 0.19999999999999996\n",
      "Kappa Annotator 1 & Annotator 3: 0.4\n",
      "Kappa Annotator 2 & Annotator 3: 0.44444444444444453\n"
     ]
    }
   ],
   "source": [
    "## TODO: Implement your solution for part 2\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "annotator1_relevance = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]  \n",
    "annotator2_relevance = [1, 1, 1, 0, 1, 0, 0, 1, 1, 1]  \n",
    "annotator3_relevance = [1, 0, 0, 0, 1, 0, 0, 1, 1, 0] \n",
    "\n",
    "def calculate_and_print_kappa(annotator1, annotator2, annotator_name1, annotator_name2):\n",
    "    kappa_score = cohen_kappa_score(annotator1, annotator2)\n",
    "    print(f\"Kappa {annotator_name1} & {annotator_name2}: {kappa_score}\")\n",
    "\n",
    "def main():\n",
    "    # Calculate kappa scores\n",
    "    calculate_and_print_kappa(annotator1_relevance, annotator2_relevance, \"Annotator 1\", \"Annotator 2\")\n",
    "    calculate_and_print_kappa(annotator1_relevance, annotator3_relevance, \"Annotator 1\", \"Annotator 3\")\n",
    "    calculate_and_print_kappa(annotator2_relevance, annotator3_relevance, \"Annotator 2\", \"Annotator 3\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
